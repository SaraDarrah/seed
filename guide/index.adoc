= Seed  User Guide
Emily Smith <emily.smith@appliedis.com>; Jonathan Meyer <jonathan.meyer@appliedis.com>
:toc: left
:toclevels: 5
:stylesheet: styles/html.css
:sectlinks:
:sectnums:
:sectnumlevels: 5
:icons: font
:docinfo:

== Purpose

This guide introduces data scientists and algorithm developers to National Geospatial-Intelligence Agency (NGA) Research's Seed and Scale technologies. This suite provides Data Scientists and Algorithm Developers with the ability to complete algorithm proof of concepts, test and refine algorithms over time, validate new algorithms against massive volumes of historic data and integrate final algorithms into a workflow.  It allows decision makers to validate data flows and look for consistent data volumes.   

Seed is a general standard to aid in the discovery and consumption of a discrete unit of work contained within a Docker
image. The Seed standard clearly defines the requirements and interface of an algorithm, ensuring that local testing is consistent with operational environments. It allows data scientists to focus their expertise on solving domain problems and rely on the toolchain we
provide to ensure their algorithm is packaged properly for operational use. Seed can be used throughout the development
lifecycle to build, test and package within a simulated environment that closely emulates targeted operational
environments. This reduces risk and allows the algorithm requirements to be explicitly defined by the developers who
best understand their processing needs.

SCALE allows data scientists and algorithm developers to publist a Seed compliant algorithm and complete algorithm proof of concepts, test and refine algorithms over time and integrate final algorithms into a system to easily share work within their community. Scale also ensures decision makers and system administrators are able to visually monitor data flows and ensure reliable data processing.  It enables a true DevOps environment for algorithm development and cloud transition.

This document will focus primarily on using the Seed Command-Line Interface (CLI) to build, test and publish your
algorithm as a Seed compliant Docker image. The Seed toolchain consists of the CLI, Silo, Vault and any processing
system that can consume Seed images - Scale being the primary one. Our recommendation is to familiarize yourself with
using Seed by working through the tutorial included within this document. Detailed reference on more advanced topics is
provided and special attention should be given to the security section.

== Expectations

Before using Seed, you should have a working familiarity with developing code using modern tools. Minimally we expect a
working knowledge of Docker and Linux fundamentals. This guide is written with the assumption that you are using a Linux
workstation. The Seed CLI is heavily reliant on Docker to build and package Seed images (Docker image with Seed
metadata), so it is highly recommended that you have superuser access.

*Add instructions for Docker and Seed CLI installation. Make sure we specify version requirements.*

== Tutorial

Following this step-by-step tutorial will quickly get you up and running with Seed and demonstrate the steps needed to
arrive at a complete Seed image. By the end of this guide, you will be able to:

- Build a Seed compliant algorithm
- Leverage the Seed CLI to ensure Seed compliance and build a Seed compliant Docker image
- Leverage the Seed CLI to test your Seed algorithm
- Leverage the Seed CLI to publish your Seed algorithm
- Understand next steps to automated distributed execution

=== Compliance

For your algorithm to be compatible with Seed, it must satisfy the following criteria:

* *Run on Linux.* There is no language limitation other than it must be able to execute under Linux. You can use the
Docker base image of your choice. Alpine and CentOS are the preferred Linux flavors.
* *Command-line Invocation.* Seed provides input via either arguments or environment variables. If your algorithm is
prompting for input from a user, the job will continue to wait until it times out. This includes no display popups such
as error dialogs, file selection menus, splash screens, etc. In the event where a display device is required for
rendering data, a pseudo device must be used.
* *Configurable.* Your algorithm will be run in a standalone container, therefore absolute file paths must not be
embedded in the source code for your development environment. Necessary file paths should be passable into the algorithm
either via an environment variable or from the command line.
* *Reporting.* While this isnâ€™t required, it is ideal if your algorithm outputs its progress and errors to the
console and returns an appropriate exit code. Unique exit codes should be used for failures that can be anticipated. If
failures are not captured appropriately, Seed will only be able to identify a general algorithm error, which may make
debugging issues more difficult.

=== Sample Algorithm

The foundation of a Seed image is the algorithm that it contains. Everything that follows is informed by the
requirements of your unique algorithm: the inputs it requires, the outputs it generates and the resources that are
required to perform the computations. For this guide we are going to use a very simple algorithm, one which takes a
single file and dumps the first _N_ bytes as hexadecimal. We are going to output the bytes both to the console and write
them to a file. This novel example provides an example of how to accomplish the following:

* Accept a file input
* Accept an integer type input
* Write to the console
* Write to an output file

We are going to write our algorithm using a couple basic Linux commands. Use your favorite text editor or IDE to create
`hex-dump.sh` file:

```
#!/usr/bin/env sh

## Usage:
## hex-dump.sh INPUT_FILE BYTE_COUNT OUTPUT_DUMP_FILE

INPUT_FILE=$1
BYTE_COUNT=$2
OUTPUT_DUMP_FILE=$3

echo "Invoked with command line: $*"

head -c $BYTE_COUNT $INPUT_FILE | od -x | tee $OUTPUT_DUMP_FILE

echo "Execution complete."
```

On Linux, this script can be executed immediately, but we are going to package in a Docker image. Create the following
`Dockerfile` in a directory adjacent to the above script:

```
FROM busybox

COPY hex-dump.sh /
```

With these 2 files, we can create our initial Docker containerized sample algorithm. Issue the following terminal
commands to build and run:

```
sudo docker build -t test .
sudo docker run --rm test sh hex-dump.sh hex-dump.sh 5 output-file.txt
```

You can see what this would look like at the command line:

*Insert screen shot*

Let's recap what we've done here.

1. We wrote a simple script that consumes 3 positional parameters: input file path, byte count, and output file path
1. Our script invokes a few basic linux executables to extract the number of bytes specified on the command line and
output them to the console and write them to a file.
1. We wrote a basic Dockerfile that identified a base image and copied our script into it.
1. We build a Docker image of our own and called it `test`.
1. Finally, we launch a container from our `test` image and passed it the required positional parameters directly.

There are some observations we should make about what we just accomplished.

1. We consumed the script we wrote as the input. The primary reason for this is so that we didn't have to concern
ourselves with getting a data file into the running container. This would have required a Docker volume mount.
1. We prefixed our call to the script with `sh` so that we didn't have to worry about setting the execute bit properly.
1. We did not validate that the `output-file.txt` was written. It exists within the container, but since we used `--rm`
flag with our docker command, the container was removed upon command completion.

With the `test` Docker image created, we could share this with other people on our local machine. We could also tag it
and push it to a remote registry (hub.docker.com, quay.io, etc.) and others would be able to run it. For our basic
algorithm example, this is fairly simple, but what if we have a more complicated algorithm with specific resource
requirements? What if our algorithm requires large supporting reference datasets? What if we need to leverage runtime
licenses that must be carefully protected? What if we want all of these requirements to be explicitly documented and
transparent to the consumers of your algorithm? This is where Seed provides what you need.

=== Seed Initialization

Continuing on from our previously crafted sample algorithm, let's get started with the definition of the basic Seed
manifest. A Seed manifest is the document that defines what your algorithm's purpose is, who created it, the interface
your algorithm provides, and what resource requirements it has. When you are building a Seed image your
`seed.manifest.json` will commonly reside next to your projects `Dockerfile`. To simplify the initial construction of
this file you can use the `seed init` command from within your code directory:

*Insert image of seed init use*

The created file includes all common sections of the manifest and can be revised to properly reflect your specific
algorithm. Let's start by updating the manifest (`seed.manifest.json`) for our algorithm:

```
{
  "seedVersion": "1.0.0",
  "job": {
    "name": "file-as-hex",
    "jobVersion": "1.0.0",
    "packageVersion": "1.0.0",
    "title": "File as Hex",
    "description": "Reads any arbitrary file and writes and prints N bytes as their hexadecimal representation",
    "maintainer": {
      "name": "Jonathan Meyer",
      "organization": "Applied Information Sciences",
      "email": "jonathan.meyer@appliedis.com"
    },
    "timeout": 3600,
    "interface": {
      "command": "sh hex-dump.sh ${INPUT_FILE} ${BYTE_COUNT} ${OUTPUT_DIR}/output.txt",
      "inputs": {
        "files": [
          {
            "name": "INPUT_FILE",
            "required": true
          }
        ],
        "json": [
          {
            "name": "BYTE_COUNT",
            "type": "integer",
            "required": true
          }
        ]
      },
      "outputs": {
        "files": [
          {
            "name": "OUTPUT_FILE",
            "pattern": "*.txt"
          }
        ]
      }
    },
    "resources": {
      "scalar": [
        { "name": "cpus", "value": 0.1 },
        { "name": "mem", "value": 128.0, "inputMultiplier": 2.0 }
      ]
    }
  }
}
```

There are a number of specific settings we've made here that are worth highlighting.

1. `job.interface.command`. This setting is the crux of the manifest and defines exactly what command is issued on
container launch. As you can see, it mirrors the Docker command we ran in the previous section. The primary difference
now is the use of environment variables. These variable names correspond to the `name` values within the
`job.interface.inputs` and `job.interface.outputs` objects.
1. `${INPUT_FILE}`. The Seed specification contract ensures that this variable will be populated with an absolute path
to the input since we have marked it as a required input.
1. `${BYTE_COUNT}`. The Seed specification contract ensures that this variable will be populated with an integer value
to the input since we have given it an explicit type and marked it as a required input.
1. `${OUTPUT_DIR}`. Where did this variable come from? We mentioned an `OUTPUT_FILE` under
`job.interface.outputs.files`, but what is this? Seed provides some contextual values that ensure there are consistent
locations for output capture. *REF ADDITIONAL VARIABLES* The `OUTPUT_DIR` environment variable is provided to all jobs
and any file products must be placed under this location. The `pattern` expression for `OUTPUT_FILE` is rooted at it and
all patterns defined are relative to that location. This is why we tell our job to write to `${OUTPUT_DIR}/output.txt`
and our `pattern` is defined as `*.txt`.
1. `job.resources.scalar`. One of the considerable advantages of using Seed CLI is that it can emulate the resource
constraints that will be placed on your algorithm in a cluster environment. We've given a fractional CPU requirement and
small amount of memory. The one point of interest here is use of the `inputMultiplier` setting. This informs Seed to
allocate memory (MiBs) in proportion to the total size of inputs files (MiBs). In other words, if our `INPUT_FILE` is 4
MiBs the allocated memory will be: 128.0 MiBs + (2.0 * 4 MiBs) = 136 MiBs.

In the next section, we will cover how we can use the CLI to bundle our Seed manifest with our Docker image to provide
a self-describing, reusable, distributable package.

=== Validate & Build

Providing validation and injection of the Seed manifest when building the final product is critical to ensuring
adherence to the specification. The CLI allows you to validate a standalone manifest file, as well as apply validation
as part of the build process. Let's perform a build of our job at this point to see this in action:

```
seed build
```

The first step of the build is to apply validation. We can see the file that is being validated against the schema. We
are also informed that our resources section does not contain all the recommended resource objects. Our build did
successfully complete and we can see the `com.ngageoint.seed.manifest` LABEL that contains our serialized manifest as
the final step of the Docker build process. Let's address the warning regarding disk resource by updating our manifest
as follows:

```
{
  "seedVersion": "1.0.0",
  "job": {
    "name": "file-as-hex",
    "jobVersion": "1.0.0",
    "packageVersion": "1.0.0",
    "title": "File as Hex",
    "description": "Reads any arbitrary file and writes and prints N bytes as their hexadecimal representation",
    "maintainer": {
      "name": "Jonathan Meyer",
      "organization": "Applied Information Sciences",
      "email": "jonathan.meyer@appliedis.com"
    },
    "timeout": 3600,
    "interface": {
      "command": "sh hex-dump.sh ${INPUT_FILE} ${BYTE_COUNT} ${OUTPUT_DIR}/output.txt",
      "inputs": {
        "files": [
          {
            "name": "INPUT_FILE",
            "required": true
          }
        ],
        "json": [
          {
            "name": "BYTE_COUNT",
            "type": "integer",
            "required": true
          }
        ]
      },
      "outputs": {
        "files": [
          {
            "name": "OUTPUT_FILE",
            "pattern": "*.txt"
          }
        ]
      }
    },
    "resources": {
      "scalar": [
        { "name": "cpus", "value": 0.1 },
        { "name": "mem", "value": 128.0, "inputMultiplier": 2.0 },
        { "name": "disk", "value": 10.0 }
      ]
    }
  }
}
```

We've added a very minimal disk requirement of 10 MiBs to resolve the warning. This space is only to accommodate any
temporary storage needed as part of the job execution beyond the storage required to write the input files to disk -
that storage will already be accounted for by Seed. Since our job is merely performing an analysis over the file stream
we will not have any appreciable need for temporary storage.

Now that our manifest is updated, lets explicitly perform a validation to ensure our warnings are resolved:

```
seed validate
```

With the warnings corrected, let's create a new build:

```
seed build
```

With a complete Seed image now created, we can continue on to run our job using the resulting Seed image. We can see
that the CLI is preparing us to run a common subsequent command with an example invocation:
`seed run -i INPUT_FILE=sample_file -j BYTE_COUNT=8`

=== Run

The `seed run` command provides the bulk of the functionality within the CLI and is where we can ensure our job is ready
to run in an operational environment. By leveraging `seed run` we can be confident that the job we publish behaves
consistently with our mental model we've used to define our interface and requirements in the `seed.manifest.json`.
Let's try a simple example to demonstrate the information the command can provide to guide in proper invocation:

```
$ seed run
INFO: Image name not specified. Attempting to use local manifest: .
INFO: Found manifest: /Users/jmeyer/code/seed/guide/example/seed.manifest.json
INFO: Retrieving seed manifest from file-as-hex-1.0.0-seed:1.0.0 LABEL=com.ngageoint.seed.manifest
normalName: INPUT_FILE
ERROR: Error occurred processing inputs arguments.
ERROR: Incorrect input data files key/values provided. -i arguments should be in the form:
  seed run -i KEY1=path/to/file1 -i KEY2=path/to/file2 ...
The following input file keys are expected, but were not provided:
  INPUT_FILE
```

*TODO: Update above snippet when the CLI is update to properly note all missing inputs*

We can see that the `seed run` command inferred the needed image from our current directory since there was a local
manifest, which was then used to find the Seed image built from it. The CLI is also able to identify the inputs that are
required, but we failed to provide. Let's properly specify these inputs and see if our image behaves as we'd expect:

```
$ seed run -i INPUT_FILE=seed.manifest.json -j BYTE_COUNT=128
INFO: Image name not specified. Attempting to use manifest: .
INFO: Found manifest: /Users/jmeyer/code/seed/guide/example/seed.manifest.json
INFO: Retrieving seed manifest from file-as-hex-1.0.0-seed:1.0.0 LABEL=com.ngageoint.seed.manifest
normalName: INPUT_FILE
INFO: /Users/jmeyer/code/seed/guide/example/output-file-as-hex-1.0.0-seed_1.0.0-2019-11-20T08_08_17-05_00 not found; creating directory...
INFO: Running Docker command:
docker run -v /Users/jmeyer/code/seed/guide/example/seed.manifest.json:/Users/jmeyer/code/seed/guide/example/seed.manifest.json -e INPUT_FILE=/Users/jmeyer/code/seed/guide/example/seed.manifest.json -v /Users/jmeyer/code/seed/guide/example/output-file-as-hex-1.0.0-seed_1.0.0-2019-11-20T08_08_17-05_00:/Users/jmeyer/code/seed/guide/example/output-file-as-hex-1.0.0-seed_1.0.0-2019-11-20T08_08_17-05_00 -e OUTPUT_DIR=/Users/jmeyer/code/seed/guide/example/output-file-as-hex-1.0.0-seed_1.0.0-2019-11-20T08_08_17-05_00 -e BYTE_COUNT=128 -e ALLOCATED_CPUS=0.100000 -m 1025m -e ALLOCATED_MEM=1025 -e ALLOCATED_DISK=10.000000 file-as-hex-1.0.0-seed:1.0.0 sh hex-dump.sh /Users/jmeyer/code/seed/guide/example/seed.manifest.json 128 /Users/jmeyer/code/seed/guide/example/output-file-as-hex-1.0.0-seed_1.0.0-2019-11-20T08_08_17-05_00/output.txt
Invoked with command line: /Users/jmeyer/code/seed/guide/example/seed.manifest.json 128 /Users/jmeyer/code/seed/guide/example/output-file-as-hex-1.0.0-seed_1.0.0-2019-11-20T08_08_17-05_00/output.txt
0000000 0a7b 2020 7322 6565 5664 7265 6973 6e6f
0000020 3a22 2220 2e31 2e30 2230 0a2c 2020 6a22
0000040 626f 3a22 7b20 200a 2020 2220 616e 656d
0000060 3a22 2220 6966 656c 612d 2d73 6568 2278
0000100 0a2c 2020 2020 6a22 626f 6556 7372 6f69
0000120 226e 203a 3122 302e 302e 2c22 200a 2020
0000140 2220 6170 6b63 6761 5665 7265 6973 6e6f
0000160 3a22 2220 2e31 2e30 2230 0a2c 2020 2020
0000200
Execution complete.
INFO: file-as-hex-1.0.0-seed:1.0.0 run took 1.343549206s
INFO: Validating output files found under /Users/jmeyer/code/seed/guide/example/output-file-as-hex-1.0.0-seed_1.0.0-2019-11-20T08_08_17-05_00...
SUCCESS: 1 files found for output OUTPUT_FILE:
	/Users/jmeyer/code/seed/guide/example/output-file-as-hex-1.0.0-seed_1.0.0-2019-11-20T08_08_17-05_00/output.txt
```

*TODO: Update command line if we update -j flag to -i*

A complete run of our job!  There is a lot to unpack that the CLI has accomplished for us here, so let's review:

- Directory for output data was created prior to launch. The CLI creates a date stamped directory to avoid any name
collision during subsequent executions. This is mounted into the container from the host when Docker container is
launched.
- `OUTPUT_DIR` environment variable is set on container launch to match the output volume that is being mounted at
runtime to provide output capture.
- The input file `seed.manifest.json` we've specified is explicitly mounted into the container at run-time.
- `INPUT_FILE` environment variable is set on container launch to inject the absolute file path relative to the
container context. This is why we indicate inputs via environment variable syntax in our `job.interface.command` value
of the `seed.manifest.json`.
- `BYTE_COUNT` environment variable is set on container launch to inject the value we specify for our JSON input type.
- Complete `docker run` statement is output to help identify the exact invocation command Seed CLI uses to launch your
Seed image. You can see the resource requirements identified as environment variables as well. Commonly this will not
be needed, but it is worth noting their presence especially for JVM applications that may benefit from explict
understanding of their memory constraints. *Move into "note" sidebar*
- Following the output of our job, we can see the CLI validate that an output file was written in a location that
matches the pattern we defined under `job.interface.outputs.files`.

Once we've gotten to this point in testing our job, we can leverage more advanced features of the `seed run` command to
further validate performance or exercise it against test data-sets.

=== Publish

After we've tested our job, we will commonly want to share it so that it can consumed by others. Seed supports various
registry backends commonly used in the Docker ecosystem. Docker Hub is a managed registry that makes it easy to publish
your Seed image without configuring any additional services of your own. Before you can publish, you'll need to register
for an account at https://hub.docker.com, once you've done that, we can continue.

The following command will publish our Seed built and tested image to Docker Hub:
*TODO: Simplify this command example once sane defaults are applied.*

```
$ seed publish -r index.docker.io -O gisjedi -u gisjedi -p "not-really-my-password"
INFO: Image name not specified. Attempting to use manifest: .
INFO: Found manifest: /Users/jmeyer/code/seed/guide/example/seed.manifest.json
WARNING! Using --password via the CLI is insecure. Use --password-stdin.
Docker login warning: WARNING! Using --password via the CLI is insecure. Use --password-stdin.

Login Succeeded
INFO: Tagging image file-as-hex-1.0.0-seed:1.0.0 as index.docker.io/file-as-hex-1.0.0-seed:1.0.0
INFO: Running Docker command:
docker tag file-as-hex-1.0.0-seed:1.0.0 index.docker.io/file-as-hex-1.0.0-seed:1.0.0
INFO: Performing docker push index.docker.io/file-as-hex-1.0.0-seed:1.0.0
INFO: Running Docker command:
docker push index.docker.io/file-as-hex-1.0.0-seed:1.0.0
The push refers to repository [docker.io/library/file-as-hex-1.0.0-seed]
28d9b1eb0588: Pushed
adab5d09ba79: Pushed
1.0.0: digest: sha256:5af9528db02c8cff65100805374fa36d86f7626584e3d21a28acb2f49342b25f size: 734
INFO: Removing local image index.docker.io/gisjedi/file-as-hex-1.0.0-seed:1.0.0
INFO: Running Docker command:
docker rmi index.docker.io/gisjedi/file-as-hex-1.0.0-seed:1.0.0
Untagged: index.docker.io/gisjedi/file-as-hex-1.0.0-seed:1.0.0
Untagged: index.docker.io/gisjedi/file-as-hex-1.0.0-seed@sha256:5af9528db02c8cff65100805374fa36d86f7626584e3d21a28acb2f49342b25f
```

As can be seen from the console, we are internally performing a number of operations to publish the image. We attach
an appropriate tag to the physical Docker image to comply with the specification that reflect the remote registry
`index.docker.io` and organization `gisjedi`. This is followed by a push of the image and cleanup of the remote tags.
This leaves our local environment with only the image names we've built for our use.

We can confirm this 

== Reference

=== Installation

=== Use Cases

==== Multi-file bundles

==== Reference Data

==== Secret Data

=== Security

=== Optimization

=== Best Practices

* *Log everything.* Not having direct access to the file system of your algorithm means your only means for feedback on
what is happening inside your container is through console output. Take full advantage of standard output / error to
indicate any progress or errors you wish visibility into. Some languages (such as Python) may require you to specify
that output should not be buffered until process exits. This will facilitate live viewing of output with longer running
processes.
* *Privilege step-down.* Docker images we use often are set to use the `root` user by default. This is not a good

